<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Gamer Bao</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="Gamer Bao">
<meta property="og:url" content="http://bcyyu.wang/index.html">
<meta property="og:site_name" content="Gamer Bao">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Gamer Bao">
<meta name="twitter:description">
  
    <link rel="alternative" href="/atom.xml" title="Gamer Bao" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/icon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="/img/icon.png" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Gamer Bao</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						<div class="icon-wrap icon-link hide" data-idx="2">
							<div class="loopback_l"></div>
							<div class="loopback_r"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						<li>友情链接</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
							<li><a href="/tags/随笔">随笔</a></li>
				        
							<li><a href="/tags/Hadoop">Hadoop</a></li>
				        
							<li><a href="/tags/mysql">Mysql</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/bao2313120/" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="http://weibo.com/1805575780/profile?rightmod=1&wvr=6&mod=personinfo" title="weibo">weibo</a>
					        
								<a class="rss" target="_blank" href="/#" title="rss">rss</a>
					        
								<a class="zhihu" target="_blank" href="http://www.zhihu.com/people/xu-zheng-yang-27" title="zhihu">zhihu</a>
					        
								<a class="mail" target="_blank" href="/391514467@qq.com" title="mail">mail</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Hadoop/" style="font-size: 20px;">Hadoop</a> <a href="/tags/mysql/" style="font-size: 15px;">mysql</a> <a href="/tags/随笔/" style="font-size: 10px;">随笔</a>
					</div>
				</section>
				
				
				
				<section class="switch-part switch-part3">
					<div id="js-friends">
					
			          <a target="_blank" class="main-nav-link switch-friends-link" href="http://blog.jamespan.me/">潘家邦</a>
			        
			        </div>
				</section>
				

				
				
				<section class="switch-part switch-part4">
				
					<div id="js-aboutme">游戏创业者，坚持做自己！</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Gamer Bao</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="/img/icon.png" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">Gamer Bao</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
					<li><a href="/tags/随笔">随笔</a></li>
		        
					<li><a href="/tags/Hadoop">Hadoop</a></li>
		        
					<li><a href="/tags/mysql">Mysql</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/bao2313120/" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="http://weibo.com/1805575780/profile?rightmod=1&wvr=6&mod=personinfo" title="weibo">weibo</a>
			        
						<a class="rss" target="_blank" href="/#" title="rss">rss</a>
			        
						<a class="zhihu" target="_blank" href="http://www.zhihu.com/people/xu-zheng-yang-27" title="zhihu">zhihu</a>
			        
						<a class="mail" target="_blank" href="/391514467@qq.com" title="mail">mail</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap">
  
    <article id="post-Compass项目架构变化" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/09/08/Compass项目架构变化/" class="article-date">
  	<time datetime="2015-09-08T03:43:37.000Z" itemprop="datePublished">2015-09-08</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/09/08/Compass项目架构变化/">Compass项目架构变化</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="前版本">前版本</h3><p><strong>roles</strong>:</p>
<ul>
<li>trackserver        </li>
<li>master</li>
</ul>
<p><strong>处理日志脚本</strong></p>
<p>trackserver生成log-[m1-9]-date文件名的日志文件，定时执行batchHiveData.js，处理后日期的生成log-hive-date文件，过期日志放在log-out/目录下。</p>
<p><strong>load日志脚本</strong></p>
<p>master在处理日志脚本执行完成后，通过batch-load-hive-data.sh.<br>scp log-hive-date 及log-out/的数据到master主机，并按照正常数据和过期的数据的区别按日期load到hive中。<br>之后，用sqoop，load-user-data.sh将mysql中的user相关的快照表load到hive中。</p>
<p>###新版本<br><strong>roles</strong>  </p>
<ul>
<li>trackserver</li>
<li>flume-agent</li>
<li><p>flume-collect</p>
<p>trackserver 产生log-[1-9] 文件名的符合hive需求的文件，flume-agent 通过execSource ，用tailf这些文件变化将log日志传输到flume-collect,使用hdfssinks 将日志流式存入hdfs中。然后依据数据格式建立不同的hive表结构进行数据查询。</p>
<p><strong>注意点</strong></p>
</li>
</ul>
<ol>
<li><p>因为公司数据项目繁多，需要按照action和date对hive进行分区，我们hive采用外部表的方式，所以需要对log日志进行处理，我使用regex_extractor，将log日志的action和time抽取出来，放到head中，通过events传到sinks中。注意：我们的log日志中记录的是10位的timestamp，而flume中的时间占位符识别的是13位的timestamp，所以我对日志中的timestamp进行了*1000的处理。进而通过actionsub做一级分区，而datesub做二级分区。</p>
</li>
<li><p>因为hive外部表的元数据分区信息需要受到插入，否则哪怕location到准确目录，也是读取不到数据的。我采用的方案是采用定时任务，每天执行一次批量插入当前日期前后7天的分区信息。</p>
</li>
</ol>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
    <article id="post-track原始数据流程方案对比" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/09/08/track原始数据流程方案对比/" class="article-date">
  	<time datetime="2015-09-08T03:17:47.000Z" itemprop="datePublished">2015-09-08</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Compass项目架构变化">Compass项目架构变化</h2><h3 id="前版本">前版本</h3><p><strong>roles</strong>:</p>
<ul>
<li>trackserver        </li>
<li>master</li>
</ul>
<p><strong>处理日志脚本</strong></p>
<p>trackserver生成log-[m1-9]-date文件名的日志文件，定时执行batchHiveData.js，处理后日期的生成log-hive-date文件，过期日志放在log-out/目录下。</p>
<p><strong>load日志脚本</strong></p>
<p>master在处理日志脚本执行完成后，通过batch-load-hive-data.sh.<br>scp log-hive-date 及log-out/的数据到master主机，并按照正常数据和过期的数据的区别按日期load到hive中。<br>之后，用sqoop，load-user-data.sh将mysql中的user相关的快照表load到hive中。</p>
<p>###新版本<br><strong>roles</strong>  </p>
<ul>
<li>trackserver</li>
<li>flume-agent</li>
<li><p>flume-collect</p>
<p>trackserver 产生log-[1-9] 文件名的符合hive需求的文件，flume-agent 通过execSource ，用tailf这些文件变化将log日志传输到flume-collect,使用hdfssinks 将日志流式存入hdfs中。然后依据数据格式建立不同的hive表结构进行数据查询。</p>
<p><strong>注意点</strong></p>
</li>
</ul>
<ol>
<li><p>因为公司数据项目繁多，需要按照action和date对hive进行分区，我们hive采用外部表的方式，所以需要对log日志进行处理，我使用regex_extractor，将log日志的action和time抽取出来，放到head中，通过events传到sinks中。注意：我们的log日志中记录的是10位的timestamp，而flume中的时间占位符识别的是13位的timestamp，所以我对日志中的timestamp进行了*1000的处理。进而通过actionsub做一级分区，而datesub做二级分区。</p>
</li>
<li><p>因为hive外部表的元数据分区信息需要受到插入，否则哪怕location到准确目录，也是读取不到数据的。我采用的方案是采用定时任务，每天执行一次批量插入当前日期前后7天的分区信息。</p>
</li>
</ol>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
    <article id="post-flume搭建" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/08/12/flume搭建/" class="article-date">
  	<time datetime="2015-08-12T09:39:51.000Z" itemprop="datePublished">2015-08-12</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/08/12/flume搭建/">flume搭建</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>游戏公司需要分析游戏用户的所有行为，现在的项目是一个消除类的休闲游戏，需要记录分析用户的每一次拉框操作。在游戏内测期间，为了快速开发，直接简单粗暴的用了mysql来记录。如今北美用户量是200W左右，每天log的数量在亿量级。so,mysql been gived up!</p>
<p>第一阶段，我使用了hadoop+hive+sqoop2的架构来简单粗暴的搭建了一套日志生成处理分析的BI系统，懂行的人知道这显然是很low的！so，这里介绍下<a href="https://flume.apache.org/" target="_blank" rel="external">flume</a>得使用。</p>
<p><strong>简介</strong><br>flume是apache旗下的一套日志收集系统，现在大家使用的一般是Flume NG的版本<br>，只有一种角色就是agent。作为配置即可用的组件，有三个内容需要配置：</p>
<ul>
<li>source 作为数据来源</li>
<li>sink 处理数据去向</li>
<li>channel 连接source和sink之间的通道</li>
</ul>
<p><strong>安装</strong></p>
<p>flume显然是可以用ClouderaManager来管理安装。但是现实情况是我们不需要将所有的flume agent主机纳入Cloudera的管理中。所以可以下载包之后直接<code>tar xzvf ...</code> ,需要配置一下FLUME_HOME 和JDK的PATH。</p>
<p><strong>配置</strong></p>
<p>首先来一个官网上的demo</p>
<pre><code># example.conf: A single-node Flume configuration
# Name the components on this agent
a1.sources = r1
a1.sinks = k1
a1.channels = c1
# <span class="operator"><span class="keyword">Describe</span>/configure the <span class="keyword">source</span>
a1.sources.r1.<span class="keyword">type</span> = netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = <span class="number">44444</span>

# <span class="keyword">Describe</span> the sink
a1.sinks.k1.<span class="keyword">type</span> = logger

# <span class="keyword">Use</span> a channel which buffers <span class="keyword">events</span> <span class="keyword">in</span> <span class="keyword">memory</span>
a1.channels.c1.<span class="keyword">type</span> = <span class="keyword">memory</span>
a1.channels.c1.<span class="keyword">capacity</span> = <span class="number">1000</span>
a1.channels.c1.transactionCapacity = <span class="number">100</span>

# Bind the <span class="keyword">source</span> <span class="keyword">and</span> sink <span class="keyword">to</span> the channel
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1</span>
</code></pre><h3 id="Source">Source</h3><ol>
<li><code>avro</code> 用于监听端口采集数据(采用avro通信协议传输),一般agent之间传输时可以使用。</li>
<li><code>Thrift</code> 用于监听端口采集数据(采用Thrift通信协议传输)，同上</li>
<li><p><code>exec</code> 执行shell脚本来采集数据，一般使用：</p>
<p> <code>tail -F [file]</code></p>
<p> <code>a1.sources.r1.command = tail -F /var/log/secure</code></p>
<p> 支持对命令或者脚本的重启</p>
</li>
<li><code>jms</code> 从消息队列中获取消息</li>
<li><code>netcat</code> 监控指定端口，每一行作为一个event传输。</li>
<li><code>http</code> 支持http的post和get,需要指定handler</li>
<li><code>Scribe</code> 主要用于兼容Scribe.</li>
<li><code>syslog</code> 监听syslog，支持tcp和udp，支持多端口监听</li>
<li><code>sequence</code> 用于测试，产生自增编号的event</li>
<li><code>spooldir</code> 监控某个目录下的所有文件，将其新加入的文件作为数据源传输走；<br>每传输玩一个文件后，会被rename成其他名字（表示已经传输过）或者删掉；<br>默认监控目录下的文件具有：immutable、uniquely-named属性，否则会出错；</li>
<li><code>kafka</code> 获取kafka产生的的数据（可能后面会采用的架构）</li>
</ol>
<h3 id="Channels">Channels</h3><ol>
<li><code>memory channel</code> 消息放在内存中，提高吞吐，但不可靠，可能丢失数据</li>
<li><code>JDBC channel</code> 内置的derb数据库，对event进行了持久化，提供高可靠性；<br>看来是取代同样具有持久特性的file channel</li>
<li><code>Kafka Channel</code> 结合kafka使用</li>
<li><code>File</code> 会对数据进行持久化，保证数据安全，有损性能</li>
<li><code>SPILLABLEMEMORY</code> 类似与memory和file的折中方法，优先使用memory,剩下的就都持久化到file中等待</li>
</ol>
<h5 id="Channel_Selectors">Channel Selectors</h5><p>这里介绍一下这个<br>这里的channel Selectors主要用来处理一个source有两个及以上的的sink的时候，需要通过不同的channel来发送，这个时候就需要channel selectors .</p>
<p>官方文档上channel selectors 有两种类型:      </p>
<p>Replicating Channel Selector (default)</p>
<p>Multiplexing Channel Selector<br>这里具体是设置可以参照<a href="http://blog.csdn.net/xiao_jun_0820/article/details/38116103" target="_blank" rel="external">这篇博客</a></p>
<h3 id="Sinks">Sinks</h3><p>sinks，负责处理source来得数据。sink的种类也有很多<br>hdfs,hive,logger,Avro,Thrift,IRC,file_roll,null,Hbase,asynchbase,MorphlineSolrSink,ElasticSearchSink,Kite Dataset,Kafka.</p>
<p>因为这里没有一个个使用过，大家可以去<a href="https://flume.apache.org/FlumeUserGuide.html" target="_blank" rel="external">flume</a>官方文档上查看。我自己用的应该是Hive,所以后面应该会写一篇Hive作为sinks的详尽的文章。</p>
<p>下面给出一个测试环境的配置代码<br>测试环境有2台主机，track主机会产生日志文件储存在文件中，core主机是中心节点，用于收集数据并输出出来。</p>
<p><strong>track主机</strong></p>
<p> 文件名：flume-track.conf</p>
<pre><code><span class="title">agent</span>.sources = r1
<span class="title">agent</span>.channels = c1
<span class="title">agent</span>.sinks = s1

#<span class="type">For</span> each one <span class="keyword">of</span> the sources, the <span class="typedef"><span class="keyword">type</span> is defined</span>
<span class="title">agent</span>.sources.r1.<span class="typedef"><span class="keyword">type</span> = exec</span>

<span class="title">agent</span>.sources.r1.command = tail -f /data/track_diagon/data/log-<span class="number">9</span>-<span class="number">2015</span>-<span class="number">08</span>-<span class="number">11</span>

# <span class="type">Each</span> sink's <span class="typedef"><span class="keyword">type</span> must be defined</span>
<span class="title">agent</span>.sinks.s1.<span class="typedef"><span class="keyword">type</span> = avro</span>
<span class="title">agent</span>.sinks.s1.hostname = <span class="number">172.31</span><span class="number">.30</span><span class="number">.204</span>
<span class="title">agent</span>.sinks.s1.<span class="foreign"><span class="keyword">port</span> = 60000</span>

# <span class="type">Each</span> channel's <span class="typedef"><span class="keyword">type</span> is defined.</span>
<span class="title">agent</span>.channels.c1.<span class="typedef"><span class="keyword">type</span> = memory</span>
<span class="title">agent</span>.channels.c1.capacity = <span class="number">100</span>
# <span class="type">Other</span> config values specific to each <span class="typedef"><span class="keyword">type</span> of channel<span class="container">(<span class="title">sink</span> <span class="title">or</span> <span class="title">source</span>)</span></span>
# can be defined <span class="keyword">as</span> well
<span class="title">agent</span>.sources.r1.channels = c1
<span class="title">agent</span>.sinks.s1.channel = c1
</code></pre><p><strong>core主机</strong></p>
<p>文件名：flume-core.conf</p>
<pre><code><span class="title">agent</span>.sources = r1
<span class="title">agent</span>.channels = c1
<span class="title">agent</span>.sinks = s1

# <span class="type">For</span> each one <span class="keyword">of</span> the sources, the <span class="typedef"><span class="keyword">type</span> is defined</span>
<span class="title">agent</span>.sources.r1.<span class="typedef"><span class="keyword">type</span> = avro</span>
<span class="title">agent</span>.sources.r1.bind = <span class="number">172.31</span><span class="number">.30</span><span class="number">.204</span>
<span class="title">agent</span>.sources.r1.<span class="foreign"><span class="keyword">port</span> = 60000</span>

# <span class="type">Each</span> sink's <span class="typedef"><span class="keyword">type</span> must be defined</span>
<span class="title">agent</span>.sinks.s1.<span class="typedef"><span class="keyword">type</span> = logger</span>

# <span class="type">Each</span> channel's <span class="typedef"><span class="keyword">type</span> is defined.</span>
<span class="title">agent</span>.channels.memoryChannel.<span class="typedef"><span class="keyword">type</span> = memory</span>
<span class="title">agent</span>.channels.memoryChannel.capacity = <span class="number">1000</span>
# <span class="type">Other</span> config values specific to each <span class="typedef"><span class="keyword">type</span> of channel<span class="container">(<span class="title">sink</span> <span class="title">or</span> <span class="title">source</span>)</span></span>
# can be defined <span class="keyword">as</span> well
<span class="title">agent</span>.sources.r1.channels = c1
<span class="title">agent</span>.sinks.s1.channel = c1
</code></pre><p>然后先在core主机的flume文件价下运行：</p>
<pre><code>bin/flume-ng  agent -c <span class="keyword">conf</span> -f <span class="keyword">conf</span>/flume-core.<span class="keyword">conf</span> -<span class="keyword">n</span> agent 
</code></pre><p>然后在track主机上运行：</p>
<pre><code>bin/flume-ng  agent -c conf -f conf/flume-track<span class="class">.conf</span> -n agent -Dflume<span class="class">.root</span><span class="class">.logger</span>=INFO,console
</code></pre><p>这样如果track主机的日志文件内容增加，core主机就会输出日志文件所生成的event!</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
    <article id="post-ClouderaManager入门使用" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/08/11/ClouderaManager入门使用/" class="article-date">
  	<time datetime="2015-08-11T09:43:19.000Z" itemprop="datePublished">2015-08-11</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/08/11/ClouderaManager入门使用/">ClouderaManager入门使用</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>  因为工作原因，自己搭建Hadoop生态环境，包括hdfs，hive,sqoop2,flume在第一阶段的摸索时，使用apache系列原生的包来安装，配置，使用。磕磕绊绊花了接近半个月将整套东西应用部署到生产环境上。闲暇之后仔细研究下了各种配置，之后看到了2大神器分别是：<a href="https://ambari.apache.org/" target="_blank" rel="external">Ambari</a>和<a href="http://www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/cm_ig_install_path_a.html" target="_blank" rel="external">ClouderaManager</a>.<br>  对于Ambari,开始前虽然看到官网上说明了Ubuntu系统只支持到12.不过本着试试看看的心态研究了1天，环境搭好之后，安装<code>HDP</code>的时候系统检测那一关果然是过不去。OK，本着不跟自己过不去的原则，give up it!</p>
<p>  ClouderaManager的使用真心让我很惊喜。</p>
<h3 id="安装ClouderaManager"><strong>安装ClouderaManager</strong></h3><p><strong>这里以Ubuntu14.04系统为例</strong></p>
<p>本人很懒，Couldera显然也很懒，这个发行版就是给懒人准备的嘛！<br>所以显然使用自动安装最好 </p>
<p>1.直接在首页下载cloudera-manager-installer.bin文件 </p>
<p>2.授予可执行权限    </p>
<pre><code><span class="variable">$ </span>chmod u+x cloudera-manager-installer.bin
</code></pre><p> 3.直接sudo运行安装，这里有一个地方需要注意一下。因为Cloudera如果安装失败了卸载过程非常繁杂，所以为了避免因为断网，终端安装的是发生，可以使用screen 来安装。</p>
<pre><code><span class="variable">$ </span>sudo ./cloudera-manager-installer.bin
</code></pre><p> 安装过程中会自动安装jdk7，所以你不要预先安装。</p>
<p> 4.安装道路就是一系列的yes,ok。。安装成功后cloudera-server会自动启动，并监听<code>7180</code>端口<br> 之后就可以访问了，第一次默认登录账号是admin/admin.</p>
<p> 这里有一个地方需要注意，似乎机器性能太差的机器是无法正常运行的。我没有在官网上发现这个说法，但是我使用2核4G的机器做实验安装成功之后，启动server之后过几秒就回dead。</p>
<h3 id="安装Hadoop集群"><strong>安装Hadoop集群</strong></h3><p>在安装之前有2件事是需要大家做的。</p>
<ul>
<li>设置每台你要加入集群中的机器之间的ssh链接</li>
<li>就是在每主机的<code>/etc/hosts</code>文件里加入集群中的每台主机的内网IP和主机名。这样直接填进去搜索就可以了。</li>
</ul>
<p>以admin/admin登录界面之后，是选择主机，之后选择CDH的版本，这里一般选择默认就可以了。</p>
<p>在ssh的界面，需要指定你的cloudera-server所在机器的密钥文件。并且注定用户</p>
<p>后面就是选择hadoop服务的安装。</p>
<p>在这里有几个地方需要注意：</p>
<ul>
<li>首先Hive的元数据服务可能需要制定mysql等，这里需要在主机上<code>安装mysql的jdbc driver</code><br>,执行：</li>
</ul>
<pre><code>sudo apt-get <span class="operator"><span class="keyword">install</span> libmysql-<span class="keyword">java</span></span>
</code></pre><p>否在会在启动服务时报错误。</p>
<ul>
<li>另外一个问题就是关于cloudera5 里新出现的单用户模式，据官方文档上说是可以用单个用户执行所有的服务，但是要使用这个单个用户模式会涉及到很多的用户权限问题，我自己就在这个问题上坑了很久。</li>
</ul>
<p>后来经过实践发现可以按照<a href="http://www.cloudera.com/content/cloudera/zh-CN/documentation/core/v5-3-x/topics/install_singleuser_reqts.html?scroll=xd_583c10bfdbd326ba--69adf108-1492ec0ce48--7ade__section_n53_hd1_fq" target="_blank" rel="external">官网上</a>的说明操作，<code>注意：</code>我们采用的自动安装模式不需要进行B和C中的设置。即只操作：</p>
<pre><code>usermod -<span class="tag">a</span> -G sudo cloudera-scm
</code></pre><p>取消注释：/etc/pam.d/su 里，session required pam_limits.so。</p>
<p>其他操作则不用进行。</p>
<h3 id="技巧"><strong>技巧</strong></h3><p>经过趟坑，发现有以下几点可以避免权限错误。</p>
<ul>
<li><p>我们可以挂在一块单独的硬盘，挂载到根目录下得/data目录上，之后讲安装集群过程中所有的内容都知道这个data上，即将之前的/var/log,/var/lib目录的内容都制定到/data/cm/var/log,/data/cm/var/lib里面。并且将/data/cm的目录权限授予cloudera-scm用户。</p>
<pre><code>sudo chown cloudera-<span class="string">scm:</span>root data/
sudo chown cloudera-<span class="string">scm:</span>root cm/
</code></pre></li>
</ul>
<p>注意这里的组权限必须是root而不能是cloudera-scm，否则启动服务时会警告，虽然我也不清楚是为什么。</p>
<p>如果以上的过程你都经历了，那么恭喜你，终于不要满世界的机器去看状态和改配置文件了（大公司的哥们忽略。。）！</p>
<p>自己也刚刚开始使用，后期会继续摸索。。。</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hadoop/">Hadoop</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
    <article id="post-mysql忘记密码处理" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/08/10/mysql忘记密码处理/" class="article-date">
  	<time datetime="2015-08-10T09:31:23.000Z" itemprop="datePublished">2015-08-10</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/08/10/mysql忘记密码处理/">mysql忘记密码处理</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>工作中会使用很多的主机，偶尔用到一台很久不用的主机，需要mysql的服务，作为实验环境第一反应会去apt-get intsall mysql-server. 可是发现已经安装过。 then,what’s the password for root?</p>
<p>  <strong>进入免权限认证处理</strong></p>
<p>  <code>sudo vim /etc/mysql/my.cnf</code></p>
<p>  把<code>skip-grant-tables</code> 在[mysqld]段中。</p>
<p>  重启<code>mysql sudo service mysql restart</code></p>
<p>  然后可以直接无密码登录mysql,</p>
<pre><code>mysql -uroot;

<span class="operator"><span class="keyword">use</span> mysql;</span>

<span class="operator"><span class="keyword">update</span> <span class="keyword">user</span> <span class="keyword">set</span> <span class="keyword">password</span> = <span class="keyword">password</span>(<span class="string">'new password'</span>) <span class="keyword">where</span> <span class="keyword">user</span> = <span class="string">'root'</span>;</span>

<span class="operator"><span class="keyword">flush</span> <span class="keyword">privileges</span>;</span>

exit;
</code></pre><p>然后把之前修改的my.cnf文件改回来，之后重启MySQL服务。</p>
<p>即修改密码成功</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/mysql/">mysql</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
    <article id="post-mysql新建用户权限控制" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/08/10/mysql新建用户权限控制/" class="article-date">
  	<time datetime="2015-08-10T09:12:37.000Z" itemprop="datePublished">2015-08-10</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/08/10/mysql新建用户权限控制/">mysql新建用户权限控制</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><strong>创建用户</strong>  </p>
<p><code>create user username identified by &#39;password&#39;</code></p>
<p><strong>授权</strong></p>
<p><code>grant all privileges on databasename.* to &#39;username&#39;@&#39;localhost&#39; identified by &#39;password&#39;</code>  </p>
<p>这里如果需要远程登录则将localhost换成需要的主机名，如果是任意地点登录则为<code>%</code>， 有一点需要注意，需要在    <code>/etc/mysql/my.cnf</code> 中将</p>
<p><code>bind-address = 127.0.0.1</code> 注释掉。</p>
<h3 id="然后刷新权限">然后刷新权限</h3><p><code>flush privileges</code></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/mysql/">mysql</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
    <article id="post-开站序言" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/08/03/开站序言/" class="article-date">
  	<time datetime="2015-08-03T14:31:43.000Z" itemprop="datePublished">2015-08-03</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2015/08/03/开站序言/">开站序言</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="序言">序言</h3><ol>
<li>本人游戏公司全栈工程师一名，自己学习的东西越来越繁杂，很多琐碎的东西挤一起来很容易忘记，所以找寻了一下考虑建一个技术博客，用于记录学习的过程，也本着分享的精神，给跟我遇到同样问题的同学一个思路。额，共勉！</li>
<li>额，整理一下技术方向，首先语言方面个人比较擅长JS和JAVA，所以一些文章基本都是基于此来说明的。首先呢，我现在处于一个创业公司，公司的hadoop生态系统是又我负责搭建的，所以近期可能会偏这方面的各个组件的内容偏多。然后是游戏服务器架构方面以及代码级别的一些内容，都会慢慢的讲道。需要的同学可以联系我沟通。</li>
<li><p>在记录技术生活的同时，自己也会更新一些不实名的杂记等，可能未来会加密，但前期应该是开放的。</p>
<p> 希望我可以持续的发展我的站点。另外，感谢这个域名的妹子！</p>
</li>
</ol>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/随笔/">随笔</a></li></ul>
	</div>

      

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>







  
  
</div>
            <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2015 Gamer Bao
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
        <span id="busuanzi_container_site_pv">
    本站总访问量<span id="busuanzi_value_site_pv"></span>次
</span>
<span id="busuanzi_container_page_pv">
  本文总阅读量<span id="busuanzi_value_page_pv"></span>次
</span>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>